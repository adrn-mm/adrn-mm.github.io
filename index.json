[{"content":"Please wait until the dashboard below is loaded or you can view the full version of this dashboard in this link.\n","permalink":"http://adrian-maulana.com/visualizations/traffic-west-java/","summary":"This analytics dashboard shows the proportion of traffic alerts in the city and street of West Java. The local government can use the dashboard to monitor and get insight into their area\u0026rsquo;s traffic condition.","title":"Dashboard Traffic Alert in West Java"},{"content":"Who is Data Engineer? Data engineer is someone who builds a data-driven system so that data can be easily utilized by a company. We need data engineers because the data is scattered in many places, still raw, and too big. Data engineers are responsible for collecting, processing, and storing data so that it can be used by data scientists and analysts. The tasks of data engineer: Designing and monitoring the architecture of Data Platform and Pipeline Integrating data from multiple sources into a single source (Data Ingestion) Implementing Data Governance. Data governance is the process of managing and controlling data within a company (Data Quality, Data Security \u0026amp; Privacy, Data Access Management). Implementing Data Lifecycle Management Data Collection \u0026amp; Processing Data Storage Data Use \u0026amp; Analysis Data Deletion Data Pipeline Pipeline Components Sources Staging/Landing Data Warehouse Data Mart ETL ELT Advantages: Flexibility data formats Tranformation as needed Speed of Loading Disadvantages: Not suitable for non-cloud users Sensitive data may not comply with regulation Lower speed of analysis Data Ingestion Data ingestion is a process of transporting data from one or more sources to a target site. Stream Batch Lambda Architecture OLTP vs. OLAP Online Transaction Processing Online Analytical Processing Data Lake, Data Warehouse, \u0026amp; Data Mart Data Lake focus is on storing raw and unstructured data from various sources in a storage location, in unstructured or semi-structured formats like files, images, or streaming data, at a low cost, and providing fast access to the data. Data Warehouse focus is on creating a centralized storage location for data taken from various sources and organized in a way that can be used for analysis. Data in the data warehouse is transformed into a structured format and arranged in a star or snowflake schema, with the aim of supporting decision-making and business analysis. Data marts are a subset of the data warehouse that focus on a specific business area, such as sales or finance. They are taken from the data warehouse and presented in a format suitable for business purposes. Data marts are used to meet the specific needs of departments or for specific business analysis needs. Relational and Non-Relational Databases Relational databases consist of tables with rows and columns, which are related to each other using primary and foreign keys. The data is organized using a schema, and SQL (Structured Query Language) is used to interact with the database. Relational databases are suitable for applications that require high data integrity and complex transactions, and tools like MySQL, MS SQL Server, and PostgreSQL are commonly used. Non-relational databases, also known as NoSQL, use a more flexible data model, such as document, graph, or key-value store, and are not organized in a fixed schema. They are suitable for applications that require horizontal scalability and the ability to manage unstructured data. Tools like MongoDB, Cassandra, and Redis are commonly used for NoSQL databases. ","permalink":"http://adrian-maulana.com/blogs/data-engineering-101/","summary":"An introduction and key concepts to data engineering. It\u0026rsquo;s a concise overview for anyone seeking a basic understanding of data engineering.","title":"Data Engineering 101"},{"content":"Please wait until the dashboard below is loaded or you can view the full version of this dashboard in this link.\n","permalink":"http://adrian-maulana.com/visualizations/covid-indonesia/","summary":"This dashboard displays the development of COVID-19 cases across all provinces in Indonesia.","title":"COVID-19 Indonesia Dashboard"},{"content":"Getting Started to Data Modelling Data models provide insights into the major data subjects, attributes of the data, relationships between the data, and the business rules for the data. These are some terminologies in data modeling: Entity: A thing or concept in the real world that is represented in the database, such as a person, place, thing, or event. Attributes: Characteristics or properties that describe an entity, such as name, age, address, or date. Relationship: An association between two or more entities, which is used to represent how they are related to each other in the database. Types of Data Models These are the types of data modeling: Conceptual Data Model: Describes what the system contains in terms of entities, attributes, and relationships, without including implementation details. It provides a high-level view of the data requirements of the system. Logical Data Model: Describes how the system should be implemented, in terms of the data structures, constraints, and rules. It defines the logical relationships between entities, attributes, and relationships, and is independent of any specific database management system (DBMS). Physical Data Model: Describes how the system will be implemented using a specific DBMS system, including details such as data types, indexing, partitioning, and storage. It defines the physical storage structures and access methods for the database. Cardinality Cardinality refers to the number of relationships between two entities, and is often expressed using the minimum and maximum values. The types of cardinality relationships are: One-to-One (1:1): Each entity in the relationship is related to exactly one other entity. One-to-Many (1:N): One entity in the relationship is related to many instances of the other entity, but the reverse is not true. Many-to-Many (M:N): Each instance of each entity can be related to many instances of the other entity. Crow\u0026rsquo;s foot notation is a visual representation used in data modeling to represent cardinality relationships between entities. It uses various symbols such as lines, diamonds, and circles to represent the types of relationships and the cardinality constraints. Normalization \u0026amp; Denormalization Normalization\nA process that involves breaking down complex tables into smaller and more structured tables, following a set of rules or normal forms, such as 1NF, 2NF, and 3NF, to reduce data redundancy and improve data integrity. It can improve query performance, prevent data loss, and increase data storage efficiency, making it suitable for complex database designs that require high data integrity and allow for flexible and efficient data management. Denormalization\nA process that involves combining multiple tables or entities into one larger table or entity, eliminating relationships or connections between tables to improve query performance and simplify database design. Although it makes data reading easier for applications that require fast and easy data access, it can cause data duplication and may be difficult to maintain data integrity if there are changes to the duplicated data. As a result, it is suitable for databases with large volumes of data. Dimensional Modelling Dimensional modeling is a data warehouse design technique that organizes data into a structure that is easy to understand and efficient for data analysis. Fact and dimension are the two key concepts in dimensional modeling. Fact refers to quantitative or numerical data that can be measured, while dimension refers to the categories or attributes used to group and filter data (context). The two data schema models used in dimensional modeling are the star schema and the snowflake schema. The star schema is a simple design with one fact table and multiple dimension tables, while the snowflake schema is a more complex design that allows for more detailed analysis. Database keys are used to ensure data integrity. Primary keys can be natural or surrogate, while foreign keys are used to create relationships between tables. Policies for historical data include overwrite, maintaining unlimited history, or maintaining limited history, depending on the specific needs of the organization. ","permalink":"http://adrian-maulana.com/blogs/data-modelling/","summary":"Data modeling is an essential component in designing efficient and effective databases. So, let\u0026rsquo;s dive in and explore the fascinating world of data modeling!","title":"Data Modelling"},{"content":" Project Based Intern by BTPN Syariah Data Engineer\nFeb 2023 - Mar 2023\nDSLS Bootcamp by Data Science Indonesia Data Consultant\nJan 2023 - Mar 2023\nData Fellowship Program by IYKRA Data Engineer\nNov 2022 - Mar 2023\nCertifications AWS re/Start Graduate Certificate Credentials\nIssued Dec 2022 ","permalink":"http://adrian-maulana.com/careers/","summary":" Project Based Intern by BTPN Syariah Data Engineer\nFeb 2023 - Mar 2023\nDSLS Bootcamp by Data Science Indonesia Data Consultant\nJan 2023 - Mar 2023\nData Fellowship Program by IYKRA Data Engineer\nNov 2022 - Mar 2023\nCertifications AWS re/Start Graduate Certificate Credentials\nIssued Dec 2022 ","title":"Careers"}]